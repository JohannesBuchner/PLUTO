<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.8"/>
<title>PLUTO: Parallel Interface</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">PLUTO
   &#160;<span id="projectnumber">4.2</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.8 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="annotated.html"><span>Data&#160;Structures</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Data Structures</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Enumerations</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Macros</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Pages</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Parallel Interface </div>  </div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#sec1">1 Overview</a></li>
<li class="level1"><a href="#sec2">2 Basics</a><ul><li class="level2"><a href="#subsection1">2.1 Block Structured Meshes</a></li>
<li class="level2"><a href="#subsection2">2.2 Stencil-based Computations</a></li>
<li class="level2"><a href="#subsection3">2.3 Domain Decomposition</a></li>
</ul>
</li>
<li class="level1"><a href="#sec3">3 ArrayLib</a><ul><li class="level2"><a href="#subsection4">3.1 Usage</a></li>
<li class="level2"><a href="#subsection5">3.2 Structure and Design of AL</a></li>
</ul>
</li>
</ul>
</div>
<div class="textblock"><p><a class="anchor" id="Parallel_page"></a></p>
<p>ArrayLib (AL) is a library that supports parallel finite difference/finite volume computations on block structured meshes. It is based on the Message Passing Interface (MPI) paradigm. The purpose of AL is to provide a simple, easy-to-use tool for the rapid development of finite difference methods in simple multidimensional quadrilateral domains.</p>
<p>The AL library had been developed by Andrea Malagoli, University of Chicago in 1999. It was made publicly available by the author for research purposes only.</p>
<p>In PLUTO only some of the AL routines are used. Many of them are used as originally written, other, conversely, have been modified before use. Moreover, additional routines have been written for particular purpouses, as to perform IO in vtk format and asyncronous parallel IO.</p>
<p>In what follow, a) the AL phylosophy and b) the use of the AL routines used in PLUTO are described.</p>
<h1><a class="anchor" id="sec1"></a>
1 Overview</h1>
<p>AL is a tool to facilitate the development of stencil-based computations, typically finite-difference/finite-volume methods, on distributed memory parallel machines.</p>
<p>AL basically provides an abstraction for <b> distributed array </b> objects, and simple interfaces to the underlying MPI routines. The parallelization model adopted in AL is the usual one of distributed arrays augmented with guard cells (ghost points) to deal with boundary conditions. The size of the guard cells is determined by the stencil of the discretized differential operator.</p>
<p>AL supports both cell-centered and staggered meshes (and a combination of both), and it provides basic functionality to </p><ul>
<li>define distributed arrays; </li>
<li>update the guard cells on each processor; </li>
<li>provide conversion routine between local and global addressing of the arrays.</li>
</ul>
<p>Parallel IO routines based on MPI/IO are also provided.</p>
<p>AL was originally designed as a library, with support for C and FORTRAN interface. In PLUTO version 4.0, the AL is no longer a library. The AL routines used have been included in the source code, with support for C only.</p>
<p>The architecture of AL is inspired by similar previous developments, and in particular the BlockComm library of Gropp and Smith.</p>
<p>A <b> distributed array</b> is defined as an object and it is identified by an integer number, called <b>descriptor</b>. The user modifies the properties of the distributed array by calling appropriate functions that take the descriptor as one of their inputs. The variables internal to the object are hidden from the user, and are accessible only via such functions. A strict object-oriented architecture is not implemented, so, for example, the buffer that contains the data for the distributed array is not incorporated into the object, and it is the user's responsibility to allocate it properly. The library provides the user with basic functionality decompose, and manipulate block-structured arrays distributed across several processors. This way, the user needs only to have a limited knowledge of the MPI paradigm.</p>
<h1><a class="anchor" id="sec2"></a>
2 Basics</h1>
<p>The basic object in AL is a <b>regular block-structured array</b> that may be distributed across multiple processors. As it is usual, the array is augmented with <b>guard cells</b> or <b>ghost points</b> in order to implement boundary conditions on a given computational stencil. In this section, the basic ideas of stencil-based computations on regular meshes are reviewed, and the preliminary concepts and conventions that used in AL routine are introduced.</p>
<h2><a class="anchor" id="subsection1"></a>
2.1 Block Structured Meshes</h2>
<p>A regular rectangular domain that can be mapped onto a cartesian grid is often defined as a <b>block-structured mesh</b>. The domain is defined by and interior <img class="formulaInl" alt="$ \Omega $" src="form_9.png"/>, and by a boundary <img class="formulaInl" alt="$ \partial\Omega $" src="form_10.png"/>. For the sake of simplicity, let's assume that the domain is discretized using a uniform spacing <img class="formulaInl" alt="$ h $" src="form_11.png"/> in all spatial directions. For example, let's consider the 2D domain: <img class="formulaInl" alt="$ (x,y) \in [0, L_x] \otimes [0,L_y]\in R^2 $" src="form_12.png"/>, and let's assume that it is discretized in <img class="formulaInl" alt="$ N_x $" src="form_13.png"/> by <img class="formulaInl" alt="$ N_y $" src="form_14.png"/> cells with edge size <img class="formulaInl" alt="$ h $" src="form_11.png"/>, so that <img class="formulaInl" alt="$ N_x = L_x / h $" src="form_15.png"/> and <img class="formulaInl" alt="$ N_y = L_y / h $" src="form_16.png"/></p>
<div class="image">
<img src="UserMa4.gif" alt="UserMa4.gif"/>
</div>
 <div align="center"> <b>Figure 1:</b> Example of a block structured mesh with <img class="formulaInl" alt="$ N_x $" src="form_13.png"/> by <img class="formulaInl" alt="$ N_y$" src="form_17.png"/> with <img class="formulaInl" alt="$ N_x=8 $" src="form_18.png"/> and <img class="formulaInl" alt="$ N_y=8 $" src="form_19.png"/>.<br />
 The physical boundaries of the mesh are marked by the thick border,<br />
 an extra layer of guard cells (ghost points) is added outside of the physical domain. </div><p>As shown in figure 1, the physical boundary of the array, the cartesian domain <img class="formulaInl" alt="$ [0, L_x] \otimes [0,L_y]$" src="form_20.png"/>, is marked by the heavier border. The figure also shows the additional guard cells that are added outside of the physical domain in order to complete the computational stencil at the boundary (see next section).</p>
<p>We can distinguish between several types of variables that can be defined on this mesh:</p>
<ul>
<li><b>Cell-centered</b> variables: namely variables that are defined at the center of each cell. </li>
<li><b>Staggered</b> variables: namely variables defined at the edges or corners of the cells. Formally, a variable is staggered along a given dimension if it is displaced by <img class="formulaInl" alt="$ h/2 $" src="form_21.png"/> with respect to the center of the cell (thus a variable staggered in X and Y would be defined at the cell corners, while a variable staggered in X only would be defined at the X-edges of the cell. See figure 2).</li>
</ul>
<p>Therefore, if the physical domain is decomposed into <img class="formulaInl" alt="$ N_x $" src="form_13.png"/> by <img class="formulaInl" alt="$ N_y $" src="form_14.png"/> cells, a <b>cell-centered</b> variable will have size <img class="formulaInl" alt="$ N_x \times N_y $" src="form_22.png"/>, while a <b>staggered</b> variable defined along the X-edges of the cell will have size <img class="formulaInl" alt="$ (N_x+1) \times N_y$" src="form_23.png"/>.</p>
<p>Figure 2 illustrates the location of the collocation points for both a <b>cell-centered</b> variable (on the left) and for <b>staggered</b> variables (on the right).</p>
<div class="image">
<img src="UserMa6.gif" alt="UserMa6.gif"/>
</div>
 <div align="center"> <b>Figure 2:</b> Examples of cell-centered (left) and staggered variables (right). </div><h2><a class="anchor" id="subsection2"></a>
2.2 Stencil-based Computations</h2>
<p>The discretized operators used in finite difference and finite volume computations can be characterized by a <em>computational stencil</em>, which describes the number and distribution of cells required for the update of a given cell.</p>
<p>For example, consider the usual 5-point discrete Laplacian operator, which is a 2nd order approximation to the Laplacian operator on a <img class="formulaInl" alt="$ N_x \times N_y $" src="form_22.png"/> mesh:</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\[ \Large{ \nabla \phi = \frac{1}{h^2} \big( \phi_{i+1,j} + \phi_{i-1,j} + \phi_{i,j+1} + \phi_{i,j-1} - \phi_{i,j}\big) + O(h^2) \qquad i=1,N_x,\quad j=1,N_y\Large} \]" src="form_24.png"/>
</p>
<p>This operator can be described as a 5-point stencil operator on a <img class="formulaInl" alt="$ N_x \times N_y $" src="form_22.png"/> mesh augmented with one layer of ghost points around each dimension of the mesh. During a calculation, the ghost points are filled with values appropriate in order to satisfy the given boundary conditions (see figure 3).</p>
<div class="image">
<img src="UserMa7.gif" alt="UserMa7.gif"/>
</div>
 <div align="center"> <b>Figure 3:</b> The stencil representation of the 5-point 2nd order Laplacian operator.</div><h2><a class="anchor" id="subsection3"></a>
2.3 Domain Decomposition</h2>
<p>The most common way to parallelize a stencil based computation on a block structured mesh as the one represented in figure 1 is to decompose the global array in sub-arrays that can be assigned independently to each processors. In turn, the sub-arrays on each processors are augmented with their own layer of ghost points in order to enable the update of the internal points. Figure 4 shows an example of the decomposition of the array onto 4 processors:</p>
<div class="image">
<img src="UserMa9.gif" alt="UserMa9.gif"/>
</div>
 <div align="center"> <b>Figure 4:</b> Example of decomposition of a two-dimensional array distributed among 4 processors.<br />
 Note that the indexed of the array refer only to the interior points,<br />
 while the allocated array would have to include the ghost points as well. </div><p>In this example, the original array is decomposed in 4 sub-arrays of equal size, and each sub-array is augmented with its own layer of ghost points on each processors (or nodes, as we use the terms interchangeably). If the original 8 x 8 array is A(0:7, 0:7), where we use the C convention to start indexes at 0, then each node would receive a 4 x 4 sub-array A(0:3, 0:3). On each node, the sub-arrays can be addressed using two types of indexes:</p>
<ul>
<li><b> Local indexes: </b> the indexes that address the local buffer. In this example (0:3,0:3). These ghost points are returned by calling the function <a class="el" href="al__proto_8h.html#af982a243da61b4c1627f9b5e3a77d983">AL_Get_lbounds()</a>. </li>
<li><b> Global indexes: </b> the indexes that define the global address of the local sub-array. For example, on node 2 in the figure the global indexes are (0:3,4:7). These ghost points are returned by calling the function <a class="el" href="al__proto_8h.html#a8db5ce906d7688fd3bd371c692df9ded">AL_Get_bounds()</a>.</li>
</ul>
<p>Typically, the local indexes are used in local do-loops on each processor, while the global indexes are used to compute the global coordinates of a grid cell.</p>
<p>Given such domain decomposition, a code on each node will function almost exactely like a standard single-processor code. A typical update loop will look like:</p>
<pre>
For n=0, n_iterations do
    Update_boundaries()
    Apply_operator()
    Perform_IO()
    ...
End for
</pre><p>The parallelism enters mainly inside the Update_boundaries() routine. In fact, the boundary ghost points on each processor are of two types:</p>
<ul>
<li><b> Physical boundary ghost points:</b> when the local ghost cells overlap with the global ghost cells. </li>
<li><b> Inter-processors boundaries ghost points:</b> when the local ghost cells overlap with interior grid points of a sub-array from a neighbor processor (see Fig. 5).</li>
</ul>
<p><b> Physical boundary ghost points </b> are updated in the usual way by assigning values that fulfill the chosen boundary conditions.</p>
<p><b> Inter-processors boundaries ghost </b> points are filled by exchanging data among neighbor processors, as is shown in Fig. 5 below.</p>
<div class="image">
<img src="UserMa11.gif" alt="UserMa11.gif"/>
</div>
 <div align="center"> <b>Figure 5:</b> Example of exchange of inter-processors ghost points. Rows of interior points are sent to neighbor processors, where they are received and copied on the local layer of ghost points. </div><p>The function AL_Is_boundary(isz, is_gbeg, is_gend) [<a class="el" href="al__boundary_8c.html#a2f5e4b5302e1957cc7a6d7298da901ec">AL_Is_boundary()</a>] returns two integer arrays, is_gbeg, is_gend, that are set to AL_TRUE (AL_FALSE) if the given layer of ghost cells for a given dimension is (is not) overlapping with the physical boundaries.</p>
<p>The data exchange is accomplished by sending messages among the processors using the MPI message passing standard. The actual calls to the message passing routines is hidden into the user-callable function <a class="el" href="al__exchange_8c.html#a517147b4403c1aa07f6f577e71d28f0f">AL_Exchange()</a>.</p>
<p>This function would be called typically at the beginning of the Update_boundaries() routine as shown in this pseudo-code:</p>
<pre> 
Update_boundaries( my_data_type *array)
  ierr = AL_Exchange(array, isz)
  foreach (side_of_the_array)
     if( this_side overlaps with the global boundaries) then
         Fill_physical_boundaries()
     end if
  end for
</pre><p><b> NOTE FOR STAGGERED MESHES </b>: on staggered meshes, the internal points of the array that lie on the grid boundary between processors exist (and are updated) on both processors (see figure below). In this case, the convention is that the left processor physically owns these nodes, and that therefore the values of the updated points from the left processors over-write those computed on the right processor during the data exchange (see figure below).</p>
<div class="image">
<img src="UserMa1.gif" alt="UserMa1.gif"/>
</div>
<h1><a class="anchor" id="sec3"></a>
3 ArrayLib</h1>
<h2><a class="anchor" id="subsection4"></a>
3.1 Usage</h2>
<p>The AL routines used in PLUTO have C interface.</p>
<p>The AL subroutine follow a standard naming convention. All subroutines and functions begin with the prefix AL_ and the first letter of the rest of the name is uppercase, while the rest is lowercase. For example AL_Get_ghosts(...). Most AL subroutines return an integer error code in C.</p>
<p>AL uses MPI data types. For convenience, the MPI data types are also translated to AL internal types by replacing the MPI prefix with the AL prefix. For example, AL_FLOAT is equivalent to MPI_FLOAT. Similarly, codes for MPI communicators and operations, are also available as AL codes (e.g. AL_COMM_WORLD is the same as MPI_COMM_WORLD, and AL_SUM is the same as MPI_SUM).</p>
<p>Typically, AL is started with a call to <a class="el" href="al__init_8c.html#ace3ddff67bdb300cee59968d847c0460">AL_Init()</a>. This also calls MPI_Init(), and it starts the MPI message passing layer.</p>
<p>After this call, the user can begin to declare distributed arrays, and use them for computations. Each distributed array has an integer descriptor <b>isz</b> that points to an internal structure that contains all the information required to handle the distributed array. The descriptor is first allocated and initialized calling the function <a class="el" href="al__proto_8h.html#a859681f4e5375a0e59036625bf045474">AL_Sz_init()</a>:</p>
<pre> 
MPI_Comm Communicator;
int isz;</pre><pre>ierr = AL_Sz_init( Communicator, &amp;isz);
</pre><p>Here, Communicator is the MPI communicator which the distributed array is associated with. A MPI communicator is the group of processors among which the array is distributed.</p>
<h2><a class="anchor" id="subsection5"></a>
3.2 Structure and Design of AL</h2>
<p>AL is built using concepts inspired by the BlockComm library of W. Gropp and B. Smith, although substantial changes and re-design have been applied.</p>
<p>AL defines a single object, a <b> block-structured distributed array</b> (<b>DA</b>). A <b>DA</b> object defines a distributed array, which is augmented with several layers of ghost points. The ghost points are used to complete the definition of a computational stencil associated with a finite-difference or finite-volume operator. A <b>DA</b> object is identified by an integer descriptor <b>isz</b> which is a pointer to an internal AL structure with the information necessary to define and utilize the <b>DA</b>. The user interacts with the internal structure by manipulating the descriptor <b>isz</b> and by calling the appropriate functions (methods). This way, the user only needs to pass the <b>isz</b> descriptor to the applications subroutines, and all the information about, e.g., the parallel decomposition, can be obtained by calling the AL_Get_xxxxx routines.</p>
<p>NOTE: contrary to most object-oriented approaches, we do not associate the array buffer directly to the <b>DA</b> object. The main reason for doing this is to retain the ability to re-use the same <b>DA</b> descriptor to handle multiple variables, this saving the redundant duplication of overheads.</p>
<p>In order to allocate a <b>isz</b> descriptor, we call the function:</p>
<pre> 
MPI_Comm Communicator;
int isz;</pre><pre>ierr = AL_Sz_init( Communicator, &amp;isz);
</pre><p>Here, Communicator is the MPI communicator which the distributed array is associated with. A MPI communicator is the group of processors among which the array is distributed (typically, Communicator = MPI_WORLD_COMM ) .</p>
<p>Subsequently, the user proceeds to define the properties of the distributed array, by setting various parameters via the <b>isz</b> descriptor. These calls typically are:</p>
<table  border="0">
<tr>
<td valign="top" width="350">ierr = AL_Set_type( AL_FLOAT, n_elements, isz);  </td><td>Sets the type type and the number of elements of type type of a distributed arrayâ€™s elements. The types are essentially identical to MPI datatypes. User defined types (e.g. MPI structures) are also possible.   </td></tr>
<tr>
<td valign="top" width="350">ierr = AL_Set_dimensions( ndims, isz);  </td><td>Sets the number of dimensions of the distributed array (e.g., ndims=3)   </td></tr>
<tr>
<td valign="top" width="350">ierr = AL_Set_global_dim( gdim, isz);  </td><td>Sets the global size of the distributed array (e.g., gdim[0]=nx; gdim[1]=ny; gdim[2]=nx)   </td></tr>
<tr>
<td valign="top" width="350">ierr = AL_Set_ghosts( ghosts, isz); </td><td>Sets the size of the ghost points of the distributed array (e.g., ghosts[0]=nx; ghosts[1]=ny; ghosts[2]=nx)  </td></tr>
<tr>
<td valign="top" width="350">ierr = AL_Set_staggered_dim( stagdims, isz); </td><td>Sets the staggered dimensions of the distributed array (e.g., stagdims[0]=AL_TRUE; stagdims[1]=AL_FALSE; stagdims[2]=AL_FALSE)  </td></tr>
<tr>
<td valign="top" width="350">ierr = AL_Set_periodic_dim( periods, isz); </td><td>Sets the periodic dimensions of the distributed array. This is used by the MPI send and receive routines. (e.g., periods[0]=AL_TRUE; periods[1]=AL_FALSE; periods[2]=AL_FALSE)  </td></tr>
<tr>
<td valign="top" width="350">ierr = AL_Set_parallel_dim( pardims, isz); </td><td>Sets the parallel dimensions of the distributed array. This is used to perform the array decomposition. (e.g., pardims[0]=AL_TRUE; pardims[1]=AL_TRUE; pardims[2]=AL_TRUE)  </td></tr>
</table>
<p>Finally, after all the above properties have been defined, the call to the function <a class="el" href="al__decompose_8c.html#ad37fda7c501dc5743707cdc31fd6aa62">AL_Decompose()</a> computes and finalizes the decomposition of the distributed array.</p>
<p>At this point, all the necessary information can be retreived from the <b>isz</b> descriptor using the AL_Get_xxxxxx routines. For example:</p>
<p>ierr = AL_Get_local_dim( isz, ldims);</p>
<p>returns the local dimensions (i.e., the dimensions on the local processor) of the distributed array.</p>
<p><b> NOTE for PLUTO </b>: In PLUTO, array descriptors for both cell-centered and staggered variables are defined.</p>
<p>For a cell-centered variable, the AL routines used are: </p><ul>
<li><a class="el" href="al__proto_8h.html#a859681f4e5375a0e59036625bf045474">AL_Sz_init()</a>; </li>
<li><a class="el" href="al__proto_8h.html#ad918afdd700a6f524b418ccddd2d3947">AL_Set_type()</a>; </li>
<li><a class="el" href="al__proto_8h.html#aec9a206d494b24cddb352328eab1ddde">AL_Set_dimensions()</a>; </li>
<li><a class="el" href="al__proto_8h.html#ac95cd1197371812b1c713cc05baa3374">AL_Set_global_dim()</a>; </li>
<li><a class="el" href="al__proto_8h.html#a141ecebe62bd312edee848f8d09b52fd">AL_Set_ghosts()</a>; </li>
<li><a class="el" href="al__proto_8h.html#a7ccd7def34748f7e8672a8c735740419">AL_Set_periodic_dim()</a>; </li>
<li><a class="el" href="al__proto_8h.html#a03c5e31907a71343116802439e1f8ed1">AL_Set_parallel_dim()</a>; </li>
<li><a class="el" href="al__decompose_8c.html#ad37fda7c501dc5743707cdc31fd6aa62">AL_Decompose()</a>; </li>
<li><a class="el" href="al__proto_8h.html#afa312dbcd1282a13036a47a482f975f4">AL_Get_local_dim()</a>; </li>
<li><a class="el" href="al__proto_8h.html#a8db5ce906d7688fd3bd371c692df9ded">AL_Get_bounds()</a>; </li>
<li><a class="el" href="al__proto_8h.html#af982a243da61b4c1627f9b5e3a77d983">AL_Get_lbounds()</a>; </li>
<li><a class="el" href="al__proto_8h.html#a26566603d76b6df122693d14f3e30a8a">AL_Get_gbounds()</a>; </li>
<li><a class="el" href="al__boundary_8c.html#a2f5e4b5302e1957cc7a6d7298da901ec">AL_Is_boundary()</a>;</li>
</ul>
<p>For a staggered variable, the AL routines used are: </p><ul>
<li><a class="el" href="al__proto_8h.html#a859681f4e5375a0e59036625bf045474">AL_Sz_init()</a>; </li>
<li><a class="el" href="al__proto_8h.html#ad918afdd700a6f524b418ccddd2d3947">AL_Set_type()</a>; </li>
<li><a class="el" href="al__proto_8h.html#aec9a206d494b24cddb352328eab1ddde">AL_Set_dimensions()</a>; </li>
<li><a class="el" href="al__proto_8h.html#ac95cd1197371812b1c713cc05baa3374">AL_Set_global_dim()</a>; </li>
<li><a class="el" href="al__proto_8h.html#a141ecebe62bd312edee848f8d09b52fd">AL_Set_ghosts()</a>; </li>
<li><a class="el" href="al__proto_8h.html#a06bb98e7dfece7e83be1bcf239a6838a">AL_Set_staggered_dim()</a>; </li>
<li><a class="el" href="al__proto_8h.html#a7ccd7def34748f7e8672a8c735740419">AL_Set_periodic_dim()</a>; </li>
<li><a class="el" href="al__proto_8h.html#a03c5e31907a71343116802439e1f8ed1">AL_Set_parallel_dim()</a>; </li>
<li><a class="el" href="al__decompose_8c.html#ad37fda7c501dc5743707cdc31fd6aa62">AL_Decompose()</a>; </li>
<li><a class="el" href="al__proto_8h.html#afa312dbcd1282a13036a47a482f975f4">AL_Get_local_dim()</a>; </li>
<li><a class="el" href="al__proto_8h.html#a8db5ce906d7688fd3bd371c692df9ded">AL_Get_bounds()</a>; </li>
<li><a class="el" href="al__proto_8h.html#af982a243da61b4c1627f9b5e3a77d983">AL_Get_lbounds()</a>; </li>
<li><a class="el" href="al__proto_8h.html#a26566603d76b6df122693d14f3e30a8a">AL_Get_gbounds()</a>; </li>
<li><a class="el" href="al__boundary_8c.html#a2f5e4b5302e1957cc7a6d7298da901ec">AL_Is_boundary()</a>;</li>
</ul>
<p>The main difference is that in the staggered case, the <a class="el" href="al__proto_8h.html#a06bb98e7dfece7e83be1bcf239a6838a">AL_Set_staggered_dim()</a> is called.</p>
<p>Once the <b>isz</b> descriptor is completely defined, after the call to <a class="el" href="al__decompose_8c.html#ad37fda7c501dc5743707cdc31fd6aa62">AL_Decompose()</a>, it can be used for two main purposes.</p>
<ul>
<li>Allocate memory for the local portion of the distributed array.<br />
 This can be achieved either by calling the function: <pre>
    a = (arraytype *) AL_Allocate_array(isz);
    </pre> or by doing manually: <pre>
    ierr = AL_Get_type_size(isz, &amp;type_size);
    ierr = AL_Get_buffer(isz, &amp;buffer_size);
    a = (arraytype *)calloc(byffer_size, type_size);
    </pre></li>
</ul>
<ul>
<li>Synchronize the distributed array by the filling of the ghost points.<br />
 The synchronization is typically applied when implementing the boundary conditions in the applications. Thus, an Update_boundary routine would begin with the call to <a class="el" href="al__exchange_8c.html#a517147b4403c1aa07f6f577e71d28f0f">AL_Exchange()</a>.</li>
</ul>
<ul>
<li>I/O operations <br />
 The interface to parallel I/O (based on MPI2-IO) is given by the following routines:</li>
</ul>
<ul>
<li><a class="el" href="al__io_8c.html#a5c3bfa8247ee5f46647e83af7ad4eacd">AL_File_open()</a> : open a file associated with the <b>isz</b> descriptor;</li>
</ul>
<ul>
<li><a class="el" href="al__io_8c.html#a48ae4d7a9a2c8d34464dd917a939433d">AL_File_close()</a> : close the file associated with the <b>isz</b> descriptor;</li>
</ul>
<ul>
<li><a class="el" href="al__io_8c.html#abdb02577ccf051ce441a00d39f0adf87">AL_Write_array()</a> : write the distributed array in collective, synchronous way;</li>
</ul>
<ul>
<li><a class="el" href="al__io_8c.html#ae5cee50e67a5315b46684be8f93958dd">AL_Read_array()</a> : read the distributed array in collective, synchronous way;</li>
</ul>
<ul>
<li><a class="el" href="al__proto_8h.html#a4649241a36bc97276a2e0314b852f2a3">AL_Write_array_begin()</a> and <a class="el" href="al__proto_8h.html#a1824b850319548ef7bc3d198c037db34">AL_Write_array_end()</a> : write the distributed array in collective, asynchronous way.</li>
</ul>
<p>These I/O procedures made using <a class="el" href="al__io_8c.html#abdb02577ccf051ce441a00d39f0adf87">AL_Write_array()</a> allow only one distributed array type to be written per file. As long as the file is open, consecutive calls to <a class="el" href="al__io_8c.html#abdb02577ccf051ce441a00d39f0adf87">AL_Write_array()</a> append new data to the end of the file. </p>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Mon Aug 31 2015 12:33:06 for PLUTO by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.8
</small></address>
</body>
</html>
